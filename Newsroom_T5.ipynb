{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtwC9p1pVXzl",
    "outputId": "cfef503e-a2d9-498c-8dff-c11749a14e29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qmNbn0KjVc2N",
    "outputId": "1b20aa5f-4219-44f9-fdbb-a3a1169ec023"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Replace the path with the actual path to your file in Google Drive\n",
    "file_path = '/content/drive/My Drive/NLP/train.jsonl'\n",
    "\n",
    "# Open the .jsonl file and load data\n",
    "data = []\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NaRj0DMBVl2q",
    "outputId": "3ca19099-e694-4933-dc29-6e98160d28b9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check the first few rows to ensure it's loaded correctly\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rLfSwXBzW9GP",
    "outputId": "6fb3fdb4-675a-46b7-828a-3e1868c28c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 url category\n",
      "0  http://www.nytimes.com/2006/06/04/sports/socce...   sports\n",
      "1  http://www.nytimes.com/2005/12/24/politics/24s...    other\n",
      "2  http://www.nytimes.com/2006/04/23/business/you...    other\n",
      "3  http://www.nydailynews.com/archives/gossip/199...    other\n",
      "4  http://www.nydailynews.com/archives/entertainm...    other\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Define your categories and keywords\n",
    "categories = {\n",
    "    'architecture': ['architect', 'building', 'construction', 'structure'],\n",
    "    'food': ['recipe', 'cuisine', 'cook', 'restaurant', 'food', 'dish', 'chef', 'healthy'],\n",
    "    'entertainment': ['movie', 'show', 'music', 'celebrity', 'actor', 'tv', 'film', 'hollywood', 'cinema', 'theatre'],\n",
    "    'sports': ['sport', 'athlete', 'league', 'tournament', 'game', 'football', 'cricket', 'hockey'],\n",
    "    'technology': ['tech', 'software', 'hardware', 'programming', 'gadget', 'app', 'phone', 'laptop', 'apple', 'microsoft', 'meta']\n",
    "}\n",
    "\n",
    "# Function to extract keywords from URL\n",
    "def extract_keywords_from_url(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    path = parsed_url.path\n",
    "    keywords = re.findall(r'/([a-zA-Z0-9-]+)', path)\n",
    "    return [keyword.lower() for keyword in keywords if keyword]\n",
    "\n",
    "# Function to categorize URLs based on keywords\n",
    "def categorize_url(url):\n",
    "    url = url.lower()\n",
    "    for category, keywords in categories.items():\n",
    "        pattern = re.compile('|'.join(f'.*{re.escape(keyword)}.*' for keyword in keywords))\n",
    "        if any(pattern.match(keyword) for keyword in extract_keywords_from_url(url)):\n",
    "            return category\n",
    "    return 'other'\n",
    "\n",
    "# Apply the function to the 'url' column to create a new 'category' column\n",
    "df['category'] = df['url'].apply(categorize_url)\n",
    "\n",
    "# Display the first few rows to verify the categorization\n",
    "print(df[['url', 'category']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8EygaWdYnEl",
    "outputId": "608e5858-2895-4c77-ed2f-623474332adc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "other            807420\n",
      "entertainment     60980\n",
      "sports            59724\n",
      "technology        49978\n",
      "food              13454\n",
      "architecture       3485\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "category_counts = df['category'].value_counts()\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kH3ujEPcZKo3",
    "outputId": "b2065a4f-169d-4eaa-ce82-508110d1b99a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of technology samples: 49978\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to only include 'technology' category\n",
    "technology_df = df[df['category'] == 'technology']\n",
    "\n",
    "# Check the size of the filtered DataFrame\n",
    "print(f\"Number of technology samples: {technology_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsb0NVlPZtow"
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Custom Dataset class for loading data\n",
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=512, summary_max_len=150):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = df\n",
    "        self.max_len = max_len\n",
    "        self.summary_max_len = summary_max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        article = str(self.data['text'].iloc[index])\n",
    "        summary = str(self.data['summary'].iloc[index])\n",
    "\n",
    "        # Encode the inputs\n",
    "        input_encoding = self.tokenizer.encode_plus(\n",
    "            article,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Encode the summaries (target)\n",
    "        target_encoding = self.tokenizer.encode_plus(\n",
    "            summary,\n",
    "            max_length=self.summary_max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_encoding['input_ids'].flatten(),\n",
    "            'attention_mask': input_encoding['attention_mask'].flatten(),\n",
    "            'labels': target_encoding['input_ids'].flatten()\n",
    "        }\n",
    "\n",
    "# Create the dataset and DataLoader\n",
    "train_dataset = SummaryDataset(technology_df, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iF23GwrZz40",
    "outputId": "e1c175f0-820f-440d-a65d-23a91bc81e91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 0: 100%|██████████| 6248/6248 [13:34<00:00,  7.67it/s, loss=0.454]\n",
      "Epoch 1: 100%|██████████| 6248/6248 [13:34<00:00,  7.67it/s, loss=0.119]\n",
      "Epoch 2: 100%|██████████| 6248/6248 [13:34<00:00,  7.67it/s, loss=0.478]\n",
      "Epoch 3: 100%|██████████| 6248/6248 [13:35<00:00,  7.66it/s, loss=0.333]\n",
      "Epoch 4: 100%|██████████| 6248/6248 [13:35<00:00,  7.67it/s, loss=0.109]\n",
      "Epoch 5: 100%|██████████| 6248/6248 [13:35<00:00,  7.66it/s, loss=0.352]\n",
      "Epoch 6: 100%|██████████| 6248/6248 [13:35<00:00,  7.67it/s, loss=0.226]\n",
      "Epoch 7: 100%|██████████| 6248/6248 [13:35<00:00,  7.66it/s, loss=0.406]\n",
      "Epoch 8: 100%|██████████| 6248/6248 [13:35<00:00,  7.66it/s, loss=0.702]\n",
      "Epoch 9: 100%|██████████| 6248/6248 [13:35<00:00,  7.66it/s, loss=0.18]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize T5 model\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "G6hFspBNaA3Z",
    "outputId": "bbd2607a-20e2-4a03-ec5c-c180f0d4c5ae"
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Generate predictions\n",
    "            outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Decode the predictions and labels\n",
    "            pred_summaries = [tokenizer.decode(g, skip_special_tokens=True) for g in outputs]\n",
    "            real_summaries = [tokenizer.decode(l, skip_special_tokens=True) for l in labels]\n",
    "\n",
    "            # Compute ROUGE scores for each sample\n",
    "            for pred, real in zip(pred_summaries, real_summaries):\n",
    "                score = scorer.score(real, pred)\n",
    "                scores['rouge1'].append(score['rouge1'].fmeasure)\n",
    "                scores['rouge2'].append(score['rouge2'].fmeasure)\n",
    "                scores['rougeL'].append(score['rougeL'].fmeasure)\n",
    "\n",
    "    # Return average scores\n",
    "    avg_scores = {key: np.mean(val) for key, val in scores.items()}\n",
    "    return avg_scores\n",
    "\n",
    "# Evaluate on a sample of the technology data\n",
    "eval_dataset = SummaryDataset(technology_df.sample(1000), tokenizer)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=8)\n",
    "\n",
    "rouge_scores = evaluate(model, eval_loader)\n",
    "print(rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ytaR6bk9fkwC"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('/content/drive/MyDrive/NLP/t5-final-model')\n",
    "tokenizer.save_pretrained('/content/drive/MyDrive/NLP/t5-final-model')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
