{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c9f65d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 16 23:48:19 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-16GB           On  |   00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   45C    P0             27W /  250W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1252b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/tchavan3/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aebefb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the bart large model\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/storage/ice1/6/4/tchavan3/results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",  # Disable unnecessary logging reports\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65bd3759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the stored model from the path\n",
    "\n",
    "path = \"/storage/ice1/6/4/tchavan3/results-new/checkpoint-13495\"\n",
    "model = BartForConditionalGeneration.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6fefd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b50bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening test dataset\n",
    "\n",
    "test_df = pd.read_csv('/storage/ice1/6/4/tchavan3/technology_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4872032f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tim Cook thinks he knows how to put $59.7 bill...</td>\n",
       "      <td>Tim Cook thinks he knows how to put $59.7 bill...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "2  Tim Cook thinks he knows how to put $59.7 bill...   \n",
       "\n",
       "                                             summary  \n",
       "2  Tim Cook thinks he knows how to put $59.7 bill...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index=2\n",
    "display(test_df[['text','summary']].iloc[index:index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5003bbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tim Cook thinks he knows how to put $59.7 billion to good use\\n\\nOne of the things that’s keeping Apple’s AAPL market cap from overtaking Exxon Mobil’s XOM — besides Steve Jobs’ health problems and the world’s unquenchable thirst for petroleum products — is the fear that the company will do something stupid with the nearly $60 billion in cash and marketable securities that seems to be burning a hole in Wall Street’s pocket.\\n\\nThe Street has made it abundantly clear what it thinks Apple should do with that cash: Declare a dividend or launch a stock repurchase program or both — anything to drive up the value of institutional investors’ Apple holdings.\\n\\nWhat the analysts who work for those institutions fear is that the company will go on a buying spree and start gobbling up the wrong kind of company — like Facebook, Adobe ADBE , Yahoo YHOO , Disney DIS or Sony SNE . Those are some of the acquisition candidates that were floated in the business press last October after Jobs was asked why Apple didn’t pay dividends. He answered, perhaps unadvisedly, that the company wanted to keep its “powder dry” for those “one or more very strategic opportunities [that] may come along.”\\n\\nOf course, buying Disney or Sony is not what Jobs meant at all. Apple is not Time Warner TWX ; it doesn’t go around buying AOLs AOL . But COO Tim Cook may have had that spectacular miscommunication in mind last week when he spoke to analysts about what Apple actually does with its cash.\\n\\nOne thing he talked about was the $3.9 billion dollars worth of agreements Apple signed over the summer and fall with three unnamed companies in its supply chain. The money came in the form of prepayments and capital expenditures for process equipment and tooling — for building factories, in other words — for components he declined to specify but which most observers suspect are touchscreens like those used in the iPad.\\n\\nThe deal, he said, is similar to the one Apple cut five years ago:\\n\\n“As you probably remember,” he began, “we signed a deal with several flash [memory chip] suppliers back at the end of 2005 that totaled over $1 billion because we anticipated that flash would become increasingly important across our entire product line and increasingly important to the industry. And so we wanted to secure supply for the company.\\n\\n“We think that that was an absolutely fantastic use of Apple’s cash.”\\n\\n[Follow Philip Elmer-DeWitt on Twitter @philiped]'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['text'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c03499e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Tim Cook thinks he knows how to put $59.7 billion to good use One of the things that's keeping Apple's market cap from overtaking Exxon Mobil's -- besides Steve Jobs' health problems and the world's unquenchable thirst for petroleum products -- is the fear that the company will do something stupid with the nearly $60…\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['summary'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "70f04765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use rouge score as our metric\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "rouge_scores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "adc401e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5448/5448 [31:06<00:00,  2.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# here we generate the summary and evaluate it using ROUGE score\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=2)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1ca0cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores_tech = {metric: sum([score[metric].fmeasure for score in rouge_scores]) / len(rouge_scores) for metric in rouge_scores[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "08e3679e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.40909470272277465,\n",
       " 'rouge2': 0.28861410254455616,\n",
       " 'rougeL': 0.36272640830490555}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_scores_tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202290b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the process for architecture\n",
    "\n",
    "test_arch_df=pd.read_csv('/storage/ice1/6/4/tchavan3/architecture_test.csv')\n",
    "test_arch_df[['text','summary']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6f0caaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 419/419 [02:27<00:00,  2.84it/s]\n"
     ]
    }
   ],
   "source": [
    "rouge_scores_arch=[]\n",
    "for idx, row in tqdm(test_arch_df.iterrows(), total=test_arch_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores_arch.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8709c8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.3880782660227092,\n",
       " 'rouge2': 0.2595271434532357,\n",
       " 'rougeL': 0.3399573795628669}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_scores_arch = {metric: sum([score[metric].fmeasure for score in rouge_scores_arch]) / len(rouge_scores_arch) for metric in rouge_scores_arch[0]}\n",
    "average_scores_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27432811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When former UMass basketball player Luke Bonne...</td>\n",
       "      <td>The New Hampshire brewery joins up with the Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is living the PRISON HIGH LIFE ... at least co...</td>\n",
       "      <td>Lauryn Hill is living the PRISON HIGH LIFE ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The company posted fiscal second-quarter earni...</td>\n",
       "      <td>Darden Restaurants reported quarterly earnings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A shrimp dish at Red Lobster has a calorie cou...</td>\n",
       "      <td>According to the Center for Science in the Pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karoline Boehm Goodnick for The Boston Globe\\n...</td>\n",
       "      <td>Don’t waste one of the best parts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  When former UMass basketball player Luke Bonne...   \n",
       "1  is living the PRISON HIGH LIFE ... at least co...   \n",
       "2  The company posted fiscal second-quarter earni...   \n",
       "3  A shrimp dish at Red Lobster has a calorie cou...   \n",
       "4  Karoline Boehm Goodnick for The Boston Globe\\n...   \n",
       "\n",
       "                                             summary  \n",
       "0  The New Hampshire brewery joins up with the Ro...  \n",
       "1  Lauryn Hill is living the PRISON HIGH LIFE ......  \n",
       "2  Darden Restaurants reported quarterly earnings...  \n",
       "3  According to the Center for Science in the Pub...  \n",
       "4                  Don’t waste one of the best parts  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat the process for food\n",
    "\n",
    "test_fd_df=pd.read_csv('/storage/ice1/6/4/tchavan3/food_test.csv')\n",
    "test_fd_df[['text','summary']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ef1b706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1482/1482 [08:57<00:00,  2.75it/s]\n"
     ]
    }
   ],
   "source": [
    "rouge_scores_fd=[]\n",
    "for idx, row in tqdm(test_fd_df.iterrows(), total=test_fd_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores_fd.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "986d4684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.35419703341724823,\n",
       " 'rouge2': 0.23810069255696226,\n",
       " 'rougeL': 0.31133163982146694}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_scores_fd = {metric: sum([score[metric].fmeasure for score in rouge_scores_fd]) / len(rouge_scores_fd) for metric in rouge_scores_fd[0]}\n",
    "average_scores_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13739875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BADEN— BADEN, West Germany, Sept. 29 - A Roy a...</td>\n",
       "      <td>BADEN, West Germany, Sept. 29 - A Roy al Canad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron Rodgers can still remember his close enc...</td>\n",
       "      <td>Aaron Rodgers can still remember his close enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wallace Robinson, the 6-foot-8-inch center who...</td>\n",
       "      <td>Wallace Robinson, the 6-foot-8-inch center who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Treasurer Joe Hockey has urged first home buye...</td>\n",
       "      <td>Asked whether Sydney’s property prices are out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On Saturday, the Australian freestyler Mack Ho...</td>\n",
       "      <td>Swimmers at the Rio Games who once served susp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  BADEN— BADEN, West Germany, Sept. 29 - A Roy a...   \n",
       "1  Aaron Rodgers can still remember his close enc...   \n",
       "2  Wallace Robinson, the 6-foot-8-inch center who...   \n",
       "3  Treasurer Joe Hockey has urged first home buye...   \n",
       "4  On Saturday, the Australian freestyler Mack Ho...   \n",
       "\n",
       "                                             summary  \n",
       "0  BADEN, West Germany, Sept. 29 - A Roy al Canad...  \n",
       "1  Aaron Rodgers can still remember his close enc...  \n",
       "2  Wallace Robinson, the 6-foot-8-inch center who...  \n",
       "3  Asked whether Sydney’s property prices are out...  \n",
       "4  Swimmers at the Rio Games who once served susp...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat the process for sports\n",
    "\n",
    "test_sprt_df=pd.read_csv('/storage/ice1/6/4/tchavan3/sports_test.csv')\n",
    "test_sprt_df[['text','summary']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7dc015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6163/6163 [37:40<00:00,  2.73it/s] \n"
     ]
    }
   ],
   "source": [
    "rouge_scores_sprt=[]\n",
    "for idx, row in tqdm(test_sprt_df.iterrows(), total=test_sprt_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores_sprt.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54bb3e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.37690845173700355,\n",
       " 'rouge2': 0.24582340965838953,\n",
       " 'rougeL': 0.3236383927989171}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_scores_sprt = {metric: sum([score[metric].fmeasure for score in rouge_scores_sprt]) / len(rouge_scores_sprt) for metric in rouge_scores_sprt[0]}\n",
    "average_scores_sprt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6a73f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam Sandler and Drew Barrymore paired up pret...</td>\n",
       "      <td>Adam Sandler and Drew Barrymore are back toget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FORTUNE — Vine Alternative Investments is rais...</td>\n",
       "      <td>Vine is latest in recent string of 'income fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>updated 03/23/2015 AT 01:45 PM EDT\\n\\n•origina...</td>\n",
       "      <td>The new Late Late Show host also names an Emmy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridley Scott’s Exodus: Gods and Kings is not e...</td>\n",
       "      <td>Ridley Scott's new movie \"Exodus: Gods and Kin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You know that it’s gotten bad when Dan Rather ...</td>\n",
       "      <td>You know that it’s gotten bad when Dan Rather ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Adam Sandler and Drew Barrymore paired up pret...   \n",
       "1  FORTUNE — Vine Alternative Investments is rais...   \n",
       "2  updated 03/23/2015 AT 01:45 PM EDT\\n\\n•origina...   \n",
       "3  Ridley Scott’s Exodus: Gods and Kings is not e...   \n",
       "4  You know that it’s gotten bad when Dan Rather ...   \n",
       "\n",
       "                                             summary  \n",
       "0  Adam Sandler and Drew Barrymore are back toget...  \n",
       "1  Vine is latest in recent string of 'income fun...  \n",
       "2  The new Late Late Show host also names an Emmy...  \n",
       "3  Ridley Scott's new movie \"Exodus: Gods and Kin...  \n",
       "4  You know that it’s gotten bad when Dan Rather ...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat the process for entertainment\n",
    "\n",
    "test_ent_df=pd.read_csv('/storage/ice1/6/4/tchavan3/entertainment_test.csv')\n",
    "test_ent_df[['text','summary']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b942642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6668/6668 [39:52<00:00,  2.79it/s]  \n"
     ]
    }
   ],
   "source": [
    "rouge_scores_ent=[]\n",
    "for idx, row in tqdm(test_ent_df.iterrows(), total=test_ent_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores_ent.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b5b2938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.4015334402901717,\n",
       " 'rouge2': 0.2839945878764216,\n",
       " 'rougeL': 0.35638082869429866}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_scores_ent = {metric: sum([score[metric].fmeasure for score in rouge_scores_ent]) / len(rouge_scores_ent) for metric in rouge_scores_ent[0]}\n",
    "average_scores_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "bart_model.to(device)\n",
    "\n",
    "rouge_scores_bart=[]\n",
    "for idx, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = bart_model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores_bart.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e627984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbae9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the average scores\n",
    "\n",
    "average_scores_bart = {metric: sum([score[metric].fmeasure for score in rouge_scores_bart]) / len(rouge_scores_bart) for metric in rouge_scores_bart[0]}\n",
    "average_scores_bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_text=test_df['text'][11]\n",
    "testing_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96270b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(testing_text, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "# Generate summary\n",
    "summary_ids = bart_model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea65147",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d76175",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['summary'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c6d92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd3589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
