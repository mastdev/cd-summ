{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 16 23:48:19 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-16GB           On  |   00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   45C    P0             27W /  250W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the bart large model\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_paraphrased/\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",  # Disable unnecessary logging reports\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading the stored model from the path\n",
    "\n",
    "path = \"./results_paraphrased/checkpoint-13495\"\n",
    "model = BartForConditionalGeneration.from_pretrained(path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use rouge score as our metric\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technology Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tech_df=pd.read_csv('./technology_test.csv')\n",
    "test_tech_df[['text','summary']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5448/5448 [31:06<00:00,  2.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# here we generate the summary and evaluate it using ROUGE score\n",
    "rouge_scores_tech=[]\n",
    "for idx, row in tqdm(test_tech_df.iterrows(), total=test_tech_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=2)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores_tech.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.40909470272277465,\n",
       " 'rouge2': 0.28861410254455616,\n",
       " 'rougeL': 0.36272640830490555}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_scores_tech = {metric: sum([score[metric].fmeasure for score in rouge_scores_tech]) / len(rouge_scores_tech) for metric in rouge_scores_tech[0]}\n",
    "average_scores_tech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arch_df=pd.read_csv('./architecture_test.csv')\n",
    "test_arch_df[['text','summary']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 419/419 [02:27<00:00,  2.84it/s]\n"
     ]
    }
   ],
   "source": [
    "rouge_scores_arch=[]\n",
    "for idx, row in tqdm(test_arch_df.iterrows(), total=test_arch_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores_arch.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.3880782660227092,\n",
       " 'rouge2': 0.2595271434532357,\n",
       " 'rougeL': 0.3399573795628669}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_scores_arch = {metric: sum([score[metric].fmeasure for score in rouge_scores_arch]) / len(rouge_scores_arch) for metric in rouge_scores_arch[0]}\n",
    "average_scores_arch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Food Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When former UMass basketball player Luke Bonne...</td>\n",
       "      <td>The New Hampshire brewery joins up with the Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is living the PRISON HIGH LIFE ... at least co...</td>\n",
       "      <td>Lauryn Hill is living the PRISON HIGH LIFE ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The company posted fiscal second-quarter earni...</td>\n",
       "      <td>Darden Restaurants reported quarterly earnings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A shrimp dish at Red Lobster has a calorie cou...</td>\n",
       "      <td>According to the Center for Science in the Pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karoline Boehm Goodnick for The Boston Globe\\n...</td>\n",
       "      <td>Don’t waste one of the best parts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  When former UMass basketball player Luke Bonne...   \n",
       "1  is living the PRISON HIGH LIFE ... at least co...   \n",
       "2  The company posted fiscal second-quarter earni...   \n",
       "3  A shrimp dish at Red Lobster has a calorie cou...   \n",
       "4  Karoline Boehm Goodnick for The Boston Globe\\n...   \n",
       "\n",
       "                                             summary  \n",
       "0  The New Hampshire brewery joins up with the Ro...  \n",
       "1  Lauryn Hill is living the PRISON HIGH LIFE ......  \n",
       "2  Darden Restaurants reported quarterly earnings...  \n",
       "3  According to the Center for Science in the Pub...  \n",
       "4                  Don’t waste one of the best parts  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_fd_df=pd.read_csv('/storage/ice1/6/4/tchavan3/food_test.csv')\n",
    "test_fd_df[['text','summary']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1482/1482 [08:57<00:00,  2.75it/s]\n"
     ]
    }
   ],
   "source": [
    "rouge_scores_fd=[]\n",
    "for idx, row in tqdm(test_fd_df.iterrows(), total=test_fd_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores_fd.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.35419703341724823,\n",
       " 'rouge2': 0.23810069255696226,\n",
       " 'rougeL': 0.31133163982146694}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_scores_fd = {metric: sum([score[metric].fmeasure for score in rouge_scores_fd]) / len(rouge_scores_fd) for metric in rouge_scores_fd[0]}\n",
    "average_scores_fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sports Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BADEN— BADEN, West Germany, Sept. 29 - A Roy a...</td>\n",
       "      <td>BADEN, West Germany, Sept. 29 - A Roy al Canad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron Rodgers can still remember his close enc...</td>\n",
       "      <td>Aaron Rodgers can still remember his close enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wallace Robinson, the 6-foot-8-inch center who...</td>\n",
       "      <td>Wallace Robinson, the 6-foot-8-inch center who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Treasurer Joe Hockey has urged first home buye...</td>\n",
       "      <td>Asked whether Sydney’s property prices are out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On Saturday, the Australian freestyler Mack Ho...</td>\n",
       "      <td>Swimmers at the Rio Games who once served susp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  BADEN— BADEN, West Germany, Sept. 29 - A Roy a...   \n",
       "1  Aaron Rodgers can still remember his close enc...   \n",
       "2  Wallace Robinson, the 6-foot-8-inch center who...   \n",
       "3  Treasurer Joe Hockey has urged first home buye...   \n",
       "4  On Saturday, the Australian freestyler Mack Ho...   \n",
       "\n",
       "                                             summary  \n",
       "0  BADEN, West Germany, Sept. 29 - A Roy al Canad...  \n",
       "1  Aaron Rodgers can still remember his close enc...  \n",
       "2  Wallace Robinson, the 6-foot-8-inch center who...  \n",
       "3  Asked whether Sydney’s property prices are out...  \n",
       "4  Swimmers at the Rio Games who once served susp...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sprt_df=pd.read_csv('/storage/ice1/6/4/tchavan3/sports_test.csv')\n",
    "test_sprt_df[['text','summary']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6163/6163 [37:40<00:00,  2.73it/s] \n"
     ]
    }
   ],
   "source": [
    "rouge_scores_sprt=[]\n",
    "for idx, row in tqdm(test_sprt_df.iterrows(), total=test_sprt_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores_sprt.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.37690845173700355,\n",
       " 'rouge2': 0.24582340965838953,\n",
       " 'rougeL': 0.3236383927989171}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_scores_sprt = {metric: sum([score[metric].fmeasure for score in rouge_scores_sprt]) / len(rouge_scores_sprt) for metric in rouge_scores_sprt[0]}\n",
    "average_scores_sprt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entertainment Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam Sandler and Drew Barrymore paired up pret...</td>\n",
       "      <td>Adam Sandler and Drew Barrymore are back toget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FORTUNE — Vine Alternative Investments is rais...</td>\n",
       "      <td>Vine is latest in recent string of 'income fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>updated 03/23/2015 AT 01:45 PM EDT\\n\\n•origina...</td>\n",
       "      <td>The new Late Late Show host also names an Emmy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridley Scott’s Exodus: Gods and Kings is not e...</td>\n",
       "      <td>Ridley Scott's new movie \"Exodus: Gods and Kin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You know that it’s gotten bad when Dan Rather ...</td>\n",
       "      <td>You know that it’s gotten bad when Dan Rather ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Adam Sandler and Drew Barrymore paired up pret...   \n",
       "1  FORTUNE — Vine Alternative Investments is rais...   \n",
       "2  updated 03/23/2015 AT 01:45 PM EDT\\n\\n•origina...   \n",
       "3  Ridley Scott’s Exodus: Gods and Kings is not e...   \n",
       "4  You know that it’s gotten bad when Dan Rather ...   \n",
       "\n",
       "                                             summary  \n",
       "0  Adam Sandler and Drew Barrymore are back toget...  \n",
       "1  Vine is latest in recent string of 'income fun...  \n",
       "2  The new Late Late Show host also names an Emmy...  \n",
       "3  Ridley Scott's new movie \"Exodus: Gods and Kin...  \n",
       "4  You know that it’s gotten bad when Dan Rather ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ent_df=pd.read_csv('/storage/ice1/6/4/tchavan3/entertainment_test.csv')\n",
    "test_ent_df[['text','summary']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6668/6668 [39:52<00:00,  2.79it/s]  \n"
     ]
    }
   ],
   "source": [
    "rouge_scores_ent=[]\n",
    "for idx, row in tqdm(test_ent_df.iterrows(), total=test_ent_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores_ent.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.4015334402901717,\n",
       " 'rouge2': 0.2839945878764216,\n",
       " 'rougeL': 0.35638082869429866}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_scores_ent = {metric: sum([score[metric].fmeasure for score in rouge_scores_ent]) / len(rouge_scores_ent) for metric in rouge_scores_ent[0]}\n",
    "average_scores_ent"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
