{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>archive</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>compression</th>\n",
       "      <th>coverage</th>\n",
       "      <th>density</th>\n",
       "      <th>compression_bin</th>\n",
       "      <th>coverage_bin</th>\n",
       "      <th>density_bin</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://www.forbes.com/sites/steveschaefer/2016...</td>\n",
       "      <td>https://web.archive.org/web/2016120719id_/http...</td>\n",
       "      <td>Biotech Stocks Smacked After Trump Boasts He'l...</td>\n",
       "      <td>1970-01-01 00:33:36.120719</td>\n",
       "      <td>The post-election rebound in biotech and healt...</td>\n",
       "      <td>It turns out President Trump may be just as bi...</td>\n",
       "      <td>32.052632</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>abstractive</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://www.9news.com.au/national/2015/08/21/15...</td>\n",
       "      <td>https://web.archive.org/web/2015082119id_/http...</td>\n",
       "      <td>Joe Hockey confirms GST will apply to online p...</td>\n",
       "      <td>1970-01-01 00:33:35.082119</td>\n",
       "      <td>Treasurer Joe Hockey has announced a ten perce...</td>\n",
       "      <td>Treasurer Joe Hockey has announced a ten perce...</td>\n",
       "      <td>10.350000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>extractive</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.foxnews.com/tech/2014/04/14/review-...</td>\n",
       "      <td>https://web.archive.org/web/2014041419id_/http...</td>\n",
       "      <td>Review: Siri-like Cortana fills Windows phone gap</td>\n",
       "      <td>1970-01-01 00:33:34.041419</td>\n",
       "      <td>Microsoft corporate vice president Joe Belfior...</td>\n",
       "      <td>With the new Cortana virtual assistant, Window...</td>\n",
       "      <td>59.217391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>extractive</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://www.theguardian.com/technology/2014/nov...</td>\n",
       "      <td>https://web.archive.org/web/2014112119id_/http...</td>\n",
       "      <td>Now e-cigarettes can give you malware</td>\n",
       "      <td>1970-01-01 00:33:34.112119</td>\n",
       "      <td>E-cigarettes may be better for your health tha...</td>\n",
       "      <td>Better for your lungs, worse for your hard dri...</td>\n",
       "      <td>22.041667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>medium</td>\n",
       "      <td>low</td>\n",
       "      <td>mixed</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.foxnews.com/scitech/2010/09/29/chin...</td>\n",
       "      <td>https://web.archive.org/web/2010092919id_/http...</td>\n",
       "      <td>China's Super Train Trounces Speed Records</td>\n",
       "      <td>1970-01-01 00:33:30.092919</td>\n",
       "      <td>258 miles per hour. That's how fast China's la...</td>\n",
       "      <td>A new Chinese high-speed train broke a world s...</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>5.296296</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>mixed</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                url  \\\n",
       "0           0  http://www.forbes.com/sites/steveschaefer/2016...   \n",
       "1           1  http://www.9news.com.au/national/2015/08/21/15...   \n",
       "2           2  http://www.foxnews.com/tech/2014/04/14/review-...   \n",
       "3           3  http://www.theguardian.com/technology/2014/nov...   \n",
       "4           4  http://www.foxnews.com/scitech/2010/09/29/chin...   \n",
       "\n",
       "                                             archive  \\\n",
       "0  https://web.archive.org/web/2016120719id_/http...   \n",
       "1  https://web.archive.org/web/2015082119id_/http...   \n",
       "2  https://web.archive.org/web/2014041419id_/http...   \n",
       "3  https://web.archive.org/web/2014112119id_/http...   \n",
       "4  https://web.archive.org/web/2010092919id_/http...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Biotech Stocks Smacked After Trump Boasts He'l...   \n",
       "1  Joe Hockey confirms GST will apply to online p...   \n",
       "2  Review: Siri-like Cortana fills Windows phone gap   \n",
       "3              Now e-cigarettes can give you malware   \n",
       "4         China's Super Train Trounces Speed Records   \n",
       "\n",
       "                         date  \\\n",
       "0  1970-01-01 00:33:36.120719   \n",
       "1  1970-01-01 00:33:35.082119   \n",
       "2  1970-01-01 00:33:34.041419   \n",
       "3  1970-01-01 00:33:34.112119   \n",
       "4  1970-01-01 00:33:30.092919   \n",
       "\n",
       "                                                text  \\\n",
       "0  The post-election rebound in biotech and healt...   \n",
       "1  Treasurer Joe Hockey has announced a ten perce...   \n",
       "2  Microsoft corporate vice president Joe Belfior...   \n",
       "3  E-cigarettes may be better for your health tha...   \n",
       "4  258 miles per hour. That's how fast China's la...   \n",
       "\n",
       "                                             summary  compression  coverage  \\\n",
       "0  It turns out President Trump may be just as bi...    32.052632  0.894737   \n",
       "1  Treasurer Joe Hockey has announced a ten perce...    10.350000  1.000000   \n",
       "2  With the new Cortana virtual assistant, Window...    59.217391  1.000000   \n",
       "3  Better for your lungs, worse for your hard dri...    22.041667  0.750000   \n",
       "4  A new Chinese high-speed train broke a world s...    11.111111  0.925926   \n",
       "\n",
       "     density compression_bin coverage_bin  density_bin    category  \n",
       "0   1.315789          medium       medium  abstractive  technology  \n",
       "1  20.000000             low         high   extractive  technology  \n",
       "2  23.000000            high         high   extractive  technology  \n",
       "3   1.750000          medium          low        mixed  technology  \n",
       "4   5.296296             low       medium        mixed  technology  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('./data_merge.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "\n",
    "# Preprocess the input and output text\n",
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(examples['text'], max_length=1024, truncation=True, padding='max_length')\n",
    "    labels = tokenizer(examples['summary'], max_length=128, truncation=True, padding='max_length')\n",
    "\n",
    "    # Set labels for training\n",
    "    inputs['labels'] = labels['input_ids']\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 53978/53978 [02:26<00:00, 367.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert pandas DataFrame to Hugging Face Dataset\n",
    "hf_dataset = Dataset.from_pandas(df[['text', 'summary']])\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_datasets = hf_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\", \"summary\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_injected\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8097' max='8097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8097/8097 2:44:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.363200</td>\n",
       "      <td>0.340811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.315100</td>\n",
       "      <td>0.333827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>0.332534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# Train the model with a progress bar (tqdm is automatically included)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injected BART Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./results_injected/checkpoint-8097\"\n",
    "model = BartForConditionalGeneration.from_pretrained(path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5448/5448 [33:00<00:00,  2.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.4070902623642649,\n",
       " 'rouge2': 0.2892701118525887,\n",
       " 'rougeL': 0.36235780344345825}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "test_df = pd.read_csv('./technology_test.csv')\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "rouge_scores = []\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores.append(score)\n",
    "\n",
    "average_scores_tech = {metric: sum([score[metric].fmeasure for score in rouge_scores]) / len(rouge_scores) for metric in rouge_scores[0]}\n",
    "average_scores_tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6163/6163 [36:55<00:00,  2.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.3831651536464214,\n",
       " 'rouge2': 0.2509568424128598,\n",
       " 'rougeL': 0.3301597491044689}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv('./sports_test.csv')\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "rouge_scores = []\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores.append(score)\n",
    "\n",
    "average_scores_arch = {metric: sum([score[metric].fmeasure for score in rouge_scores]) / len(rouge_scores) for metric in rouge_scores[0]}\n",
    "average_scores_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1482/1482 [09:11<00:00,  2.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.35844792246022766,\n",
       " 'rouge2': 0.2439043821636203,\n",
       " 'rougeL': 0.31600797529629693}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv('./food_test.csv')\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "rouge_scores = []\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores.append(score)\n",
    "\n",
    "average_scores_arch = {metric: sum([score[metric].fmeasure for score in rouge_scores]) / len(rouge_scores) for metric in rouge_scores[0]}\n",
    "average_scores_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 419/419 [02:32<00:00,  2.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.37207757497468597,\n",
       " 'rouge2': 0.2431804538260892,\n",
       " 'rougeL': 0.3216438117869889}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv('./architecture_test.csv')\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "rouge_scores = []\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores.append(score)\n",
    "\n",
    "average_scores_arch = {metric: sum([score[metric].fmeasure for score in rouge_scores]) / len(rouge_scores) for metric in rouge_scores[0]}\n",
    "average_scores_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6668/6668 [40:20<00:00,  2.75it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.40024860762551817,\n",
       " 'rouge2': 0.28355068747929124,\n",
       " 'rougeL': 0.3558658323663727}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv('./entertainment_test.csv')\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "rouge_scores = []\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    inputs = tokenizer(row['text'], return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    score = scorer.score(row['summary'], predicted_summary)\n",
    "    rouge_scores.append(score)\n",
    "\n",
    "average_scores_arch = {metric: sum([score[metric].fmeasure for score in rouge_scores]) / len(rouge_scores) for metric in rouge_scores[0]}\n",
    "average_scores_arch"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
